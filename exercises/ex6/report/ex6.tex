%Exercise 4 LaTeX report for TMA 4280
\documentclass[fontsize=11pt,paper=a4,titlepage]{article}
\input{config} %config.tex file in same directory

\begin{document}

\begin{center}

% \lstlistoflistings
% \listoffigures
% \listoftables

{\huge Problem set 6}\\[0.5cm]

\textsc{\LARGE TMA4280}\\[0.5cm]
\textsc{\large Introduction to supercomputing -}\\
\textsc{\large Mandatory problem set}\\[0.6cm]

\begin{table}[h]
\centering
\begin{tabular}{ccc}
	\textsc{Christian CHAVEZ} & \textsc{Mireia DUASO} & \textsc{Erlend SIGHOLT}
\end{tabular}
\end{table}

\large{\today}
\vfill
% \section*{Abstract}
\end{center}

\todo[inline]{ABSTRACT}


\clearpage
\section{Introduction}

For the programming code belonging to this problem set, see the $\textit{ex6.c}$
and $\textit{ex6.h}$ files in the zipped archive attached to this hand-in.

For this problem set, we have written our solution in C inspired by the work of
our professor in the subject this problem set belongs to. Hence, our structures,
the general way of thinking, and the algorithms used are based on the work and
lectures done in this subject~\cite{tma4280}.

And as such, a parallelized solver for 2-Dimensional Poisson PDEs is the
objective of this problem set. It's our implementation of this solver we
describe and analyze in this report.


\section{The Poisson problem}
\label{sec:Pois-Prob}

Poisson's equation is an elliptic Partial Differential Equation (PDE) which is
used to model diffusion. It appears in electrostatics, mechanical
engineering, and theoretical physics, among many others.

The problem follows the expression

\begin{eqnarray}
	-\nabla^2 u & = & f \quad \textrm{in} \quad \Omega \\
	u & = & g \quad \textrm{on} \quad \partial\Omega
	\label{eq:Poisson}
\end{eqnarray}

where $f$ is a source function, $g$ is the boundary condition, and $\Omega$ is a
bounded domain.

\section{The Problem Discretized}
\label{sec:Prob-Discr}

We have the below system.

\begin{displaymath}
\begin{bmatrix}
	2 & -1 &  &  &  &  &  \\
	-1 & 2 & -1 &  &  &  &  \\
	 & -1 & 2 & -1 &  &  &  \\
	 &  & \ddots & \ddots & \ddots &  & \\
	 &  &  & -1 & 2 & -1 &  \\
	 &  &  &  & -1 & 2 & -1 \\
	 &  &  &  &  & -1 & 2
\end{bmatrix}
\begin{bmatrix*}[c]
	u_0 \\
	u_1 \\
	u_2 \\
	\vdots \\
	u_{n - 2} \\
	u_{n - 1} \\
	u_n
\end{bmatrix*}
=
\begin{bmatrix*}[c]
	f_0 \\
	f_1 \\
	f_2 \\
	\vdots \\
	f_{n - 2} \\
	f_{n - 1} \\
	f_n
\end{bmatrix*}
\end{displaymath}

Since we have homogeneous boundary conditions, we reduce the problem by $2$
dimensions to become an $(n - 1) \times (n - 1)$ system since $u_0 = u_n = 0$.

\section{The Implemented Solver}

This section is divided into three parts; first we describe our implementation
and analyze its complexity, then we explain how we enabled it to accept smooth
functions, before we finish this section by explaining how we confirmed that our
solver converges towards the correct answer for a given smooth function.

\subsection{Our Implementation}
\label{sec:Impl}

Our implementation is based on the fact and observation that for any Symmetric
Positive Definite (SPD) matrix, we can through the use of a Fast Fourier
Transform (FFT), more specifically the Discrete Sine Transform (DST)
algorithm, implement a solution whose algorithmic FLOP complexity should be
$\mathcal{O}(n\times log(n))$.

And since TMA4280~\cite{tma4280} is about running mathematical solvers on
super-computing-clusters, we will use the Application Program Interface (API)
of two libraries; the MessagePassingInterface (MPI) to implement this in
parallel across processes, and OpenMultiProcessing (OpenMP) to parallelize this
solver across threads.

Following, we will describe the dataflow of our implementation, which steps we
intend for it to go through, before analyzing its final FLOP and memory
complexity.

\subsubsection{Implementation Dataflow}
\label{ssec:dataflow}

Our implementation is based on the observation that the following four steps
need to happen in the solver for it to function correctly.

\begin{enumerate}

	\item \label{istep-gen} Generate the $(N - 1)^2$ unknown variables across
	all processes, by creating a matrix $\mathbf{A}$ that fills each process
	with $\approx \frac{N-1}{P},\thickspace P = Amount\thickspace of\thickspace
	Processes$, and fill each variable in $\mathbf{A}$ with values corresponding
	to the function we want to perform the 2-Dimensional Poisson operation on.

	\item \label{istep-fst1} Use the Fourier Sine Transform (FST) on each
	coloumn of the matrix within each process, thereby Fourier transforming the
	whole matrix (let's call the transposed matrix $\mathbf{B}$), before
	transposing it across all processes. The transposition requires one ``round
	of communication'' across all processes, before an inverse FST is performed
	on $\mathbf{B}$.

\todo[inline]{Make sure that step~\ref{istep-tens} is correct, and more readable.}

	\item \label{istep-tens} Perform the tensor operation based on the
	five-point stencile given from the 2D nature of the Poisson operation on
	each element $b_{ij}$ by dividing each element on its corresponding $d_i +
	d_j$, where $\mathbf{D}$ is a vector containing the eigenvalues for these
	BLEH.

	\item \label{istep-fst2} Repeat step~\ref{istep-fst1}, except now perform
	the FST on $\mathbf{B}$, transpose it back to $\mathbf{A}$, and perform the
	inverse FST on $\mathbf{A}$. $\mathbf{A}$ now represents the solution found
	to the function inputted in step~\ref{istep-gen}.

	%\label{list:impl-steps}
\end{enumerate}

The parallelization is achieved by splitting the matrix $\mathbf{A}$'s coloumns
across the processes used with the MPI API. Since the functions that perform the
FST are not parallelizable, and they need to perform the transformation on a
whole coloumn at the time, these can be parallellized by using OpenMP, running
several concurrent threads.

This division of labor fits well with the implementation, since the OpenMP tasks
can share memory, and the MPI ones should not (hence the need for its own memory
as naturally befits a process vs. a thread).

\subsubsection{Implementation Complexity}

The complexity of our implementation can be described as following with the help
of the list in subsection~\ref{ssec:dataflow}.




%section e)
\subsection{Accepting Smooth Functions}

\subsection{Correctness Convergence}

\todo[inline]{Decide if we keep this section, to analyze and report communication/FLOP, FLOPS, and so on...}

\section{Results}

\subsection{MPI Results}

\subsection{OpenMP Results}

\subsection{Combined Results}

% (f)
\section{Non-Homogenous Dirichlet Boundary Conditions}

We want to know which part of our code has to be modified if we change the
original problem, when $u \neq 0$ on $\partial\Omega$, and $\Omega = (0,1)
\times (0,1)$.

In the analytic case, to tackle the new problem we define $v$ as a new solution,

\begin{equation}
	v = u - g
\end{equation}

for some lifting function $g$. In the newly defined solution, $g$ is supposed to
set the values of $v$ along the boundaries to $0$.

If we want our code to solve the problem with these new conditions, we need to
tranform the original problem into

\begin{displaymath}
	\mathbf{A} \times (\mathbf{u} + \mathbf{u_B}) = h^2 \mathbf{f}
\end{displaymath}

where $\mathbf{A}$ will be a $(n + 1) \times (n + 1)$ matrix, $\mathbf{u}$ will
be the old solution, $\mathbf{f}$ the source, $h$ the length of the step, and
$\mathbf{u_B}$ the function that satisfies the boundary conditions.

Considering the discretization of the original problem in section~\ref{sec:Prob-Discr}, if we re-compute the left hand-side of that system, we get

\begin{displaymath}
\begin{bmatrix}
	2u_0 - u_1 \\
	- u_0 + 2u_1 - u_2 \\
	- u_1 + 2u_2 - u_3 \\
	\vdots \\
	- u_{n - 3} + 2u_{n - 2} - u_{n - 1} \\
	- u_{n - 2} + 2u_{n - 1} - u_{n} \\
	- u_{n - 1} + 2u_n
\end{bmatrix}
=
\begin{bmatrix*}[c]
	f_0 \\
	f_1 \\
	f_2 \\
	\vdots \\
	f_{n - 2} \\
	f_{n - 1} \\
	f_n
\end{bmatrix*}.
\end{displaymath}

but this system is redundant since there are $n - 1$ variables, and $n + 1$
euqations. Hence, we can remove the first and the last terms, and we only need
to add a vector to our previous matrix.

Then the system will be written as

\begin{displaymath}
\begin{bmatrix}
	2 & -1 &  &  &  &  &  \\
	-1 & 2 & -1 &  &  &  &  \\
	 & -1 & 2 &  &  &  &  \\
	 &  & \ddots & \ddots & \ddots &  & \\
	 &  &  &  & 2 & -1 &  \\
	 &  &  &  & -1 & 2 & -1 \\
	 &  &  &  &  & -1 & 2
\end{bmatrix}
\begin{bmatrix*}[c]
	u_1 \\
	u_2 \\
	\vdots \\
	u_{n - 2} \\
	u_{n - 1}
\end{bmatrix*}
+ \begin{bmatrix*}[c]
	- u_0 \\
	0 \\
	\vdots \\
	0 \\
	- u_n
\end{bmatrix*}
=
\begin{bmatrix*}[c]
	f_1 \\
	f_2 \\
	\vdots \\
	f_{n - 2} \\
	f_{n - 1}
\end{bmatrix*}.
\end{displaymath}

\section{Handling Different Domains}
%(g)

If we consider the geometry of the domain, we may want to solve the
PDE~\ref{eq:Poisson} in a rectangle $\Omega = (0, L_x) \times (0, L_y)$. To
accomplish this, we need to declare two lengths instead of our old $h$. Namely,
$h_x$ and $h_y$, which would have the same value if we considered a square, and
different values than we would get working with a rectangle.

Following the diagonalization shown in the lectures, the only change that needs
to be implemented is the following.

In the implemented tensor-operation, instead of simply summing the two
eigenvalues whose sum we divide the variable with, we need to divide each
eigenvalue with their corresponding step-lengths of the finite grid, $h_x^2$ and
$h_y^2$. This is due to the fact that we do not store our step-lengths in the
source function.

\section{Conclusion}

\todo[inline]{Summarize the best/worst results of the result chapter. Also
repeat what we can and cannot to do from Mireia's math-section.}

\bibliography{bibliography}{}
\bibliographystyle{plain}

\end{document}
